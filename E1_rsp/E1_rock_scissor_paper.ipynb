{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-7. 프로젝트: 가위바위보 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습목표: MNIST와 Sequenential Model을 배우고, 활용하여 가위바위보 분류기를 만들어 보자.\n",
    "\n",
    "### 학습과정: 데이터 준비 → 딥러닝 네트워크 설계 → 학습 → 테스트(평가)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  데이터 불러오기 + Resize 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. home/aiffel/rock_scissor_paper 안에 가위, 바위, 보 각각의 이미지 데이터를 224x224크기로 100장씩 저장해둡니다. 같은 폴더 내에 각각 20장씩의 테스트 데이터도 준비해 둡니다.\n",
    "\n",
    "2. MNIST의 알고리즘을 사용하기 위해서는 똑같이 데이터 사이즈를 28x28로 만들어주어야 하기 때문에 PIL 라이브러리 패키지를 설치합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in ./Downloads/downloads/envs/aiffel/lib/python3.7/site-packages (8.0.1)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이제 224x224의 훈련용 데이터 이미지를 28x28로 변경합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac15/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로 /home/ssac15/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로 /home/ssac15/aiffel/rock_scissor_paper/paper\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로\", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로\", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이제 mnist.load_data() 라는 함수를 이용하여 데이터의 형태를 (image,label)의 형태로 변환해 주어야 합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**한 번 이미지를 불러 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**짜잔.. 여기까지 데이터 준비-분석-전처리 과정을 무사히 마쳤으니 이제 딥러닝 네트워크 설계 단계로 넘어가 볼까요? ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  딥러닝 네트워크 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.이제 여기에서 텐서플로우 케라스(tf.keras)에서 Sequential API라는 방법을 사용할 겁니다. \n",
    "\n",
    "2.딥러닝 네트워크에 설계된 코드는 tf.keras의 Sequential API를 이용한 LeNet입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 486,666\n",
      "Trainable params: 486,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# 손글씨 분류기에서 가장 높은 정확도를 보였던 변수를 조정한 값을 사용\n",
    "n_channel_1=64 \n",
    "n_channel_2=128\n",
    "n_dense=128\n",
    "n_train_epoch=10\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "#내가 만든 모델이 어떤 구조인지 보여줘~~\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CS231n 강의에서 보앗던 alexa의 구조도와 비슷한 구조의 모델이 만들어졌음을 확인 할 수 있었습니다. (이걸 알게 된 순간에 아드레날린이 마구마구 솟구쳤습니다~~ 끼욜~)\n",
    "\n",
    "**이제 인공지능을 만들었으니, 학습을 시켜 볼 차례입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  딥러닝 네트워크 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 노드 1-4에서 손글씨 분류기를 학습시켰던 함수를 그대로 가져옵니다. \n",
    "\n",
    "2. 그대로 가져올 때, 이미지의 형태를 맞춰 주어야 합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7855 - accuracy: 0.6867\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8800\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8633\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9567\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9833\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9900\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9a3a8b5950>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "# 이미지의 형태를 (x_train, y_train)\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 처음 데이터를 준비할 때, 폴더에 만들어 두었던 20장의 테스트 이미지로  학습된 딥러닝 네트워크를 테스트해 보겠습니다.\n",
    "\n",
    "2. 이 데이터도 먼저 데이터 싸이즈 조정과 형태를 변환해 주어야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "#import os\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor_test\"\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "  \n",
    "    \n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock_test\"\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper_test\"\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검사데이터(x_test)의 이미지 개수는 60 입니다.\n",
      "x_test shape: (60, 28, 28, 3)\n",
      "y_test shape: (60,)\n"
     ]
    }
   ],
   "source": [
    "def load_testdata(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=60   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"검사데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_test, y_test)=load_testdata(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**테스트용 데이터가 준비되었으니, 위에서 훈련시킨 model을 사용하여 test_accuracy를 측정해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 1s - loss: 4.2318 - accuracy: 0.6000\n",
      "test_loss: 4.231813430786133 \n",
      "test_accuracy: 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 총평\n",
    "\n",
    "1. 딥러닝 신경망 구조를 이해할 수 있는 학습이었다. \n",
    "\n",
    "2. 텐서플로와 케라스의 활용을 해 볼 수 있어서, 코드를 처음부터 만들 수는 없지만 여러 모델을 이렇게 활용해서 만들어 봄으로써 점점 복잡한 단계의 모델도 이해하고 활용할 수 있게 될 것이라 생각한다. \n",
    "\n",
    "3. 학습 데이터의 갯수를 좀 더 늘리고 dense 값을 높이면 정확도가 더 올라갈 것이라 생각한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
